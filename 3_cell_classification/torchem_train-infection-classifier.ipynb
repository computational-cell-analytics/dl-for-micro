{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c45f7a1",
   "metadata": {},
   "source": [
    "## Train Infection Classifier\n",
    "\n",
    "In the previous lessons we have built a method for cell instance segmentation and applied it to our dataset. Now we turn to classifying the cells into infected vs. non-infected cells, based on the virus marker channel, nucleus image channel and segmentation mask for each individual cell. We will use a ResNet for this task.\n",
    "\n",
    "The goal of this lesson is to learn how to train a classification model with `torch_em`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57794921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports.\n",
    "import torch_em\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import h5py\n",
    "import napari\n",
    "import numpy as np\n",
    "\n",
    "from skimage.measure import regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e725790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to folders with the data and train/val splits.\n",
    "# If you store the data somewhere else just change the 'data_folder' variable.\n",
    "\n",
    "data_folder = \"../data\"\n",
    "train_data_folder = os.path.join(data_folder, \"train\")\n",
    "val_data_folder = os.path.join(data_folder, \"val\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eec67a4b",
   "metadata": {},
   "source": [
    "### 1. Inspect Training Data\n",
    "\n",
    "First, we visually check all the relevant training data. We will use it to construct image patches for training the classification model as follows:\n",
    "- Compute the bounding box around each cell.\n",
    "- Cut out the nucleus image, virus marker and segmentation mask for the bounding box.\n",
    "- Set all values outside the mask to zero.\n",
    "- Derive the label (infected or not infected) for the given patch from the infetion label image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce06fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary data for one training image.\n",
    "image_path = os.path.join(train_data_folder, \"gt_image_000.h5\")\n",
    "with h5py.File(image_path, \"r\") as f:\n",
    "    marker = f[\"raw/marker/s0\"][:]\n",
    "    nucleus_image = f[\"raw/nuclei/s0\"][:]\n",
    "    cells = f[\"labels/cells/s0\"][:]\n",
    "    infected_labels = f[\"labels/infected/nuclei/s0\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a15f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check it visually.\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(marker, colormap=\"red\", blending=\"additive\")\n",
    "viewer.add_image(nucleus_image, colormap=\"blue\", blending=\"additive\")\n",
    "viewer.add_labels(cells)\n",
    "viewer.add_labels(infected_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe7d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the label (infected vs. not infected) for each cell in an image.\n",
    "def extract_labels_for_cells(cells, infected_labels):\n",
    "    # First we get all non-background cell ids for this image.\n",
    "    cell_ids = np.unique(cells)[1:]\n",
    "    cell_labels = {}\n",
    "    \n",
    "    # We iterate over the ids.\n",
    "    for cell_id in cell_ids:\n",
    "        # Compute the cell mask and get the infection labels inside of it\n",
    "        cell_mask = cells == cell_id\n",
    "        infected_labels_cell = infected_labels[cell_mask]\n",
    "        # Zero means on inferction label.\n",
    "        infected_labels_cell = infected_labels_cell[infected_labels_cell != 0]\n",
    "        # If we only have zeros then skip this cell.\n",
    "        if infected_labels_cell.size == 0:\n",
    "            cell_labels[cell_id] = None\n",
    "            continue\n",
    "    \n",
    "        # The label values mean the following: 1 = infected, 2 = not infected.\n",
    "        # If there is more than one label we need to check which of the two is more prevalent.\n",
    "        label_ids, counts = np.unique(infected_labels_cell, return_counts=True)\n",
    "        # We map the label id to 0, 1 (infected, not infected) because pytorch / torch_em expects zero-based indexing.\n",
    "        if len(label_ids) == 1:\n",
    "            assert label_ids[0] in (1, 2)\n",
    "            label = label_ids[0] - 1\n",
    "        else:\n",
    "            assert label_ids.tolist() == [1, 2], str(label_ids)\n",
    "            label = 0 if counts[0] > counts[1] else 0 \n",
    "        cell_labels[cell_id] = label\n",
    "    return cell_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8b7cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply the function to get the infection labels for the cells in our current image.\n",
    "cell_infection_labels = extract_labels_for_cells(cells, infected_labels)\n",
    "\n",
    "# And use skimage regionprops to compute other properties for all cells in the image.\n",
    "props = regionprops(cells)\n",
    "\n",
    "# Now we visualize the infected labels as points, by putting a point per cell centroid and coloring it\n",
    "# according to their label using a napari points layer (see below).\n",
    "points = [prop.centroid for prop in props]\n",
    "infected_points = [\"infected\" if label == 0 else \"not-infected\" for label in cell_infection_labels.values()]\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(marker, colormap=\"red\", blending=\"additive\")\n",
    "viewer.add_image(nucleus_image, colormap=\"blue\", blending=\"additive\")\n",
    "point_layer = viewer.add_points(\n",
    "    points, properties={\"infected\": infected_points}, face_color=\"infected\", face_color_cycle=[\"orange\", \"cyan\"],\n",
    ")\n",
    "point_layer.face_color_mode = \"cycle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e0cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the training patches and labels for one image.\n",
    "def image_to_training_data(cells, marker, nucleus_image, infected_labels, apply_cell_mask=True):\n",
    "    # Compute the infection labels with the previously defined function and the region properties.\n",
    "    cell_infection_labels = extract_labels_for_cells(cells, infected_labels)\n",
    "    props = regionprops(cells)\n",
    "    \n",
    "    # Iterate over all cells in the image and extract the training patch.\n",
    "    train_image_data, train_labels = [], []\n",
    "    for prop in props:\n",
    "        cell_id = prop.label\n",
    "        \n",
    "        # Get the infection label and skip the cell if it doesn't have one.\n",
    "        label = cell_infection_labels[cell_id]\n",
    "        if label is None:\n",
    "            continue\n",
    "        \n",
    "        # Get the bounding box from the properties for this cell.\n",
    "        bbox = prop.bbox\n",
    "        bbox = np.s_[bbox[0]:bbox[2], bbox[1]:bbox[3]]\n",
    "        \n",
    "        # Cut out mask, nucleus image and virus marker for this cell.\n",
    "        cell_mask = cells[bbox] == cell_id\n",
    "        nuc_im = nucleus_image[bbox].astype(\"float32\")\n",
    "        marker_im = marker[bbox].astype(\"float32\")\n",
    "        # And se the image values outsied of the cell to 0.\n",
    "        if apply_cell_mask:\n",
    "            nuc_im[~cell_mask] = 0.0\n",
    "            marker_im[~cell_mask] = 0.0\n",
    "        \n",
    "        # Stack the 3 channels into one image and append to the training patches and labels.\n",
    "        image_data = np.stack([nuc_im, marker_im, cell_mask.astype(\"float32\")])\n",
    "        train_image_data.append(image_data)\n",
    "        train_labels.append(label)\n",
    "        \n",
    "    return train_image_data, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9939bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to our current image.\n",
    "train_image_data, train_labels = image_to_training_data(cells, marker, nucleus_image, infected_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5aa47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 5 of the training patches.\n",
    "for i in range(25, 30):\n",
    "    im_data = train_image_data[i]\n",
    "    label = train_labels[i]\n",
    "    viewer = napari.Viewer()\n",
    "    viewer.add_image(im_data[0], name=\"nucleus-channel\", colormap=\"blue\", blending=\"additive\")   \n",
    "    viewer.add_image(im_data[1], name=\"marker-channel\", colormap=\"red\", blending=\"additive\")\n",
    "    viewer.add_labels(im_data[2].astype(\"uint8\"), name=\"cell-mask\")\n",
    "    viewer.title = f\"Label: {label}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20af4026",
   "metadata": {},
   "source": [
    "### 2. Prepare Training Data\n",
    "\n",
    "Now we apply the function we just defined to all training and validation data to build the training and validation sets for our classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Function that extracts the patches and labels for all images in a folder.\n",
    "def prepare_classification_data(root):\n",
    "    images = glob(os.path.join(root, \"*.h5\"))\n",
    "    images.sort()\n",
    "\n",
    "    image_data, labels = [], []\n",
    "    for path in tqdm(images, desc=\"Prepare classification data\"):\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            marker = f[\"raw/marker/s0\"][:]\n",
    "            nucleus_image = f[\"raw/nuclei/s0\"][:]\n",
    "            cells = f[\"labels/cells/s0\"][:]\n",
    "            infected_labels = f[\"labels/infected/nuclei/s0\"][:]\n",
    "            \n",
    "        this_data, this_labels = image_to_training_data(cells, marker, nucleus_image, infected_labels)\n",
    "        image_data.extend(this_data)\n",
    "        labels.extend(this_labels)\n",
    "        \n",
    "    assert len(image_data) == len(labels)\n",
    "    return image_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65165594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training and validation set.\n",
    "train_data, train_labels = prepare_classification_data(train_data_folder)\n",
    "print(\"We have\", len(train_data), \"samples for training\")\n",
    "\n",
    "val_data, val_labels = prepare_classification_data(val_data_folder)\n",
    "print(\"We have\", len(val_data), \"samples for validation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5302bb3",
   "metadata": {},
   "source": [
    "### 3. Train the Infection Classifier\n",
    "\n",
    "And use the training and validation set to train a ResNet34 for infection classification, using the classification functionality from `torch_em`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4745f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classification functionality.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_em.classification import default_classification_loader, default_classification_trainer\n",
    "from torchvision.models.resnet import resnet34\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean shape of all training and validation patches.\n",
    "shapes = np.stack([np.array(im.shape[1:]) for im in (train_data + val_data)])\n",
    "mean_shape = np.mean(shapes, axis=0)\n",
    "print(\"Mean image shape:\", mean_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4c1ba87",
   "metadata": {},
   "source": [
    "You should see that the mean image shape is roughly 52 x 52 pixels. We determine this shape to choose a suitable shape that all patches will be resized to for training the model. This is necessary to stack the patches across the batch dimensions and train the model with a batch size that is larger than 1.\n",
    "We choose the closest multiple of 16 as common patch shape, which is 64 x 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075ed385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training and validation loader.\n",
    "batch_size = 32  # The batch size used for training.\n",
    "image_shape = (64, 64)  # The common shape all patches will be resized to before stacking them in a batch.\n",
    "num_workers = 4 if torch.cuda.is_available() else 1\n",
    "# Build the training and validation loader.\n",
    "train_loader = default_classification_loader(\n",
    "    train_data, train_labels, batch_size=batch_size, image_shape=image_shape, num_workers=num_workers,\n",
    ")\n",
    "val_loader = default_classification_loader(\n",
    "    val_data, val_labels, batch_size=batch_size, image_shape=image_shape, num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model (a resnet 34 with two output channels).\n",
    "model = resnet34(num_classes=2)\n",
    "# And build the trainer class. Here, we use the cross entropy as loss function and the accuracy error as metric.\n",
    "trainer = default_classification_trainer(\n",
    "    name=\"infection-classifier\", model=model,\n",
    "    train_loader=train_loader, val_loader=val_loader,\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    metric=lambda a, b: 1.0 - accuracy_score(a, b),\n",
    "    compile_model=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3e0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for 10.000 iterations.\n",
    "trainer.fit(10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87373720",
   "metadata": {},
   "source": [
    "As before you can open the tensorboard to monitor the progress while training via\n",
    "```\n",
    "tensorboard --logdir=logs\n",
    "```\n",
    "See `2_cell_segmentation/torchem-train-cell-membrane-segmentation` for details."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78be34a4",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Train different architectures for this task, for example a `resnet18` and a `resnet50`. Also export these models to the bioimage.io format, make sure to choose different file paths for the export so that you do not overwrite the previous exported models.\n",
    "You can also compare to training this network using only PyTorch in the `pytorch_train-infection-classifier` notebook (work in progress)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad99b917",
   "metadata": {},
   "source": [
    "### What's next?\n",
    "\n",
    "Now we can apply the trained classification model to the test images in `apply_infection_classifier`.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "538daf2f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fecba392",
   "metadata": {},
   "source": [
    "**This is not working yet!**\n",
    "\n",
    "**Skip the cells below!**\n",
    "\n",
    "#### Export the model to bioimage.io\n",
    "\n",
    "Now we also export the model to the bioimage.io format to import it in other tools that support this format.\n",
    "See the notebook `2_cell_segmentation/torchem-train-cell-membrane-segmentation` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d734bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from torch_em.util.modelzoo import export_bioimageio_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9202b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = os.path.join(data_folder, \"trained_models\")\n",
    "model_folder = os.path.join(model_root, \"infection-classification\")\n",
    "os.makedirs(model_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5981c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_, _ = next(iter(val_loader))\n",
    "input_ = input_[0:1].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b412cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"#ResNet for Covid Cell Infection Classification\n",
    "\n",
    "A model for classifying cells into infected vs. non-infected.\n",
    "\"\"\"\n",
    "\n",
    "citations = [{\"text\": \"Pape et al.\", \"doi\": \"https://doi.org/10.1002/bies.202000257\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671be5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_bioimageio_model(\n",
    "    checkpoint=\"checkpoints/infection-classifier\",\n",
    "    export_folder=model_folder,\n",
    "    input_data=input_,\n",
    "    name=\"infection_classification_model\",\n",
    "    authors=[{\"name\": \"Your Name\", \"affiliation\": \"Your Affiliation\"}],\n",
    "    tags=[\"uner\", \"cells\", \"2d\", \"immunofluorescence\", \"classification\"],\n",
    "    license=\"CC-BY-4.0\",\n",
    "    documentation=doc,\n",
    "    description=\"Classify cell membranes in IF images\",\n",
    "    cite=citations,\n",
    "    input_optional_parameters=False,\n",
    "    maintainers=[{\"github_user\": \"Your Github Handle\"}]  # alternatively you can also give your mail address\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
