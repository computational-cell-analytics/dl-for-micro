{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6871de10",
   "metadata": {},
   "source": [
    "## Apply Infection Classifier\n",
    "\n",
    "Finally, we apply the trained infection classifier to the test data, also using the cell segmentation we predicted instead of the ground-truth. We will also evaluate the accuracy of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42766aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports.\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import h5py\n",
    "import napari\n",
    "import numpy as np\n",
    "from skimage.measure import regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5ad6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to folders with the data and predictions.\n",
    "# If you store the data somewhere else just change the 'data_folder' variable.\n",
    "\n",
    "data_folder = \"../data\"\n",
    "output_folder = os.path.join(data_folder, \"predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df5add",
   "metadata": {},
   "source": [
    "### 1. Test Data Extraction\n",
    "\n",
    "We first extract the input patches and labels for the test images. We copy these functions from the previous function. With the difference that we do not skip cells that could not be assigned a label here, but instead set them to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the label (infected vs. not infected) for each cell in an image.\n",
    "def extract_labels_for_cells(cells, infected_labels):\n",
    "    # First we get all non-background cell ids for this image.\n",
    "    cell_ids = np.unique(cells)[1:]\n",
    "    cell_labels = {}\n",
    "    \n",
    "    # We iterate over the ids.\n",
    "    for cell_id in cell_ids:\n",
    "        # Compute the cell mask and get the infection labels inside of it\n",
    "        cell_mask = cells == cell_id\n",
    "        infected_labels_cell = infected_labels[cell_mask]\n",
    "        # Zero means on inferction label.\n",
    "        infected_labels_cell = infected_labels_cell[infected_labels_cell != 0]\n",
    "\n",
    "        # If we only have zeros then mark this label with -1\n",
    "        if infected_labels_cell.size == 0:\n",
    "            cell_labels[cell_id] = -1\n",
    "            continue\n",
    "    \n",
    "        # The label values mean the following: 1 = infected, 2 = not infected.\n",
    "        # If there is more than one label we need to check which of the two is more prevalent.\n",
    "        label_ids, counts = np.unique(infected_labels_cell, return_counts=True)\n",
    "        # We map the label id to 0, 1 (infected, not infected) because pytorch / torch_em expects zero-based indexing.\n",
    "        if len(label_ids) == 1:\n",
    "            assert label_ids[0] in (1, 2)\n",
    "            label = label_ids[0] - 1\n",
    "        else:\n",
    "            assert label_ids.tolist() == [1, 2], str(label_ids)\n",
    "            label = 0 if counts[0] > counts[1] else 0 \n",
    "        cell_labels[cell_id] = label\n",
    "\n",
    "    return cell_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the training patches and labels for one image.\n",
    "def image_to_training_data(cells, marker, nucleus_image, infected_labels, apply_cell_mask=True):\n",
    "    # Compute the infection labels with the previously defined function and the region properties.\n",
    "    cell_infection_labels = extract_labels_for_cells(cells, infected_labels)\n",
    "    props = regionprops(cells)\n",
    "    \n",
    "    # Iterate over all cells in the image and extract the training patch.\n",
    "    train_image_data, train_labels = [], []\n",
    "    for prop in props:\n",
    "        cell_id = prop.label\n",
    "        \n",
    "        # Get the infection label and skip the cell if it doesn't have one.\n",
    "        label = cell_infection_labels[cell_id]\n",
    "        \n",
    "        # Get the bounding box from the properties for this cell.\n",
    "        bbox = prop.bbox\n",
    "        bbox = np.s_[bbox[0]:bbox[2], bbox[1]:bbox[3]]\n",
    "        \n",
    "        # Cut out mask, nucleus image and virus marker for this cell.\n",
    "        cell_mask = cells[bbox] == cell_id\n",
    "        nuc_im = nucleus_image[bbox].astype(\"float32\")\n",
    "        marker_im = marker[bbox].astype(\"float32\")\n",
    "        # And se the image values outsied of the cell to 0.\n",
    "        if apply_cell_mask:\n",
    "            nuc_im[~cell_mask] = 0.0\n",
    "            marker_im[~cell_mask] = 0.0\n",
    "        \n",
    "        # Stack the 3 channels into one image and append to the training patches and labels.\n",
    "        image_data = np.stack([nuc_im, marker_im, cell_mask.astype(\"float32\")])\n",
    "        train_image_data.append(image_data)\n",
    "        train_labels.append(label)\n",
    "        \n",
    "    return train_image_data, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test image and test prediction paths.\n",
    "test_images = glob(os.path.join(data_folder, \"test\", \"*.h5\"))\n",
    "test_images.sort()\n",
    "test_predictions = glob(os.path.join(output_folder, \"*.h5\"))\n",
    "test_predictions.sort()\n",
    "assert len(test_images) == len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2974b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the inputs and labels for the test images.\n",
    "classification_inputs, classification_labels = [], []\n",
    "for test_image, test_prediction in zip(test_images, test_predictions):\n",
    "    with h5py.File(test_image, \"r\") as f:\n",
    "        marker = f[\"raw/marker/s0\"][:]\n",
    "        nucleus_image = f[\"raw/nuclei/s0\"][:]\n",
    "        infected_labels = f[\"labels/infected/nuclei/s0\"][:]\n",
    "    with h5py.File(test_prediction, \"r\") as f:\n",
    "        cells = f[\"segmentations/cells/watershed_based\"][:]\n",
    "    inputs, labels = image_to_training_data(cells, marker, nucleus_image, infected_labels)\n",
    "    classification_inputs.append(inputs)\n",
    "    classification_labels.append(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7c3c9",
   "metadata": {},
   "source": [
    "### 2. Prediction and Visualization for a Test Image\n",
    "\n",
    "We run prediction for one of the test images and visualize the results in napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch and model imports\n",
    "import torch\n",
    "from torch_em.classification import default_classification_loader\n",
    "from torchvision.models.resnet import resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559bcc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available, otherwise the CPU.\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d271742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the best checkpoint.\n",
    "model_path = \"checkpoints/infection-classifier/best.pt\"\n",
    "model = resnet34(num_classes=2)\n",
    "model_state = torch.load(model_path)[\"model_state\"]\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce7b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run prediction and to return the corresponding labels in a format that can be \n",
    "# evaluated by sklearn.metrics (see below).\n",
    "def predict_infection(model, inputs, labels, batch_size=128):\n",
    "    loader = default_classification_loader(\n",
    "        inputs, labels, batch_size=batch_size, image_shape=(64, 64),\n",
    "    )\n",
    "    y_pred, y_true = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            pred = model(x).cpu().numpy()\n",
    "            class_pred = np.argmax(pred, axis=1)\n",
    "            y_pred.append(class_pred)\n",
    "            y_true.append(y.numpy().squeeze())\n",
    "            \n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    y_true = np.concatenate(y_true)\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the infection predictions for the first input.\n",
    "infection_predictions, _ = predict_infection(model, classification_inputs[0], classification_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2790c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images and segmentation for the first test image again.\n",
    "with h5py.File(test_images[0], \"r\") as f:\n",
    "    marker = f[\"raw/marker/s0\"][:]\n",
    "    nucleus_image = f[\"raw/nuclei/s0\"][:]\n",
    "    infected_labels = f[\"labels/infected/nuclei/s0\"][:]\n",
    "    \n",
    "with h5py.File(test_predictions[0], \"r\") as f:\n",
    "    cells = f[\"segmentations/cells/watershed_based\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951701d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions in napari.\n",
    "props = regionprops(cells)\n",
    "\n",
    "points = [prop.centroid for prop in props]\n",
    "infected_points = [\"infected\" if pred == 0 else \"not-infected\" for pred in infection_predictions]\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(marker, colormap=\"red\", blending=\"additive\")\n",
    "viewer.add_image(nucleus_image, colormap=\"blue\", blending=\"additive\")\n",
    "point_layer = viewer.add_points(\n",
    "    points, properties={\"infected\": infected_points}, face_color=\"infected\", face_color_cycle=[\"orange\", \"cyan\"],\n",
    ")\n",
    "point_layer.face_color_mode = \"cycle\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dcde77",
   "metadata": {},
   "source": [
    "### 3. Prediction and Evaluation for the Test Set\n",
    "\n",
    "Run prediction for all test images and evaluate the accuracy of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f93bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction and labels for all images.\n",
    "y_pred, y_true = [], []\n",
    "for inputs, labels in tqdm(zip(classification_inputs, classification_labels), total=len(classification_inputs)):\n",
    "    pred, true = predict_infection(model, inputs, labels)\n",
    "    y_pred.append(pred)\n",
    "    y_true.append(true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_true = np.concatenate(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the labels and predictions for which labels are -1 (could not be mapped to either of the two labels).\n",
    "valid_labels = y_true != -1\n",
    "y_pred, y_true = y_pred[valid_labels], y_true[valid_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eee241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy.\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"The overall accuracy is:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74270d69",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "- If you have trained any other models in the previous notebook then evaluate them as well and compare the performance between the different models.\n",
    "- Use other metrics form [sklearn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) to evaluate other aspects of the results. In particular check if there are differences in the precision vs. recall and think about what this implies experimentally.\n",
    "- Check if there are any systematic differences in the scores between the different test images. If yes, check the corresponding image data and see if you can find a reason for this visually."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
