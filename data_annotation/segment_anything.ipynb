{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be4d22d",
   "metadata": {},
   "source": [
    "## Segment Anything for Data Annotation\n",
    "\n",
    "[Segment Anything](https://segment-anything.com/) is a recent model for interactive segmentation published by Meta.AI. It can be used to genrate annotations for segmentation much faster compared to painting by hand. \n",
    "\n",
    "We have build some napari tools around it in https://github.com/computational-cell-analytics/micro-sam, which we will use here to annotate some of the cells for our example data. You can find more information on this tool and further extensions to Segment Anything in [our preprint](https://www.biorxiv.org/content/10.1101/2023.08.21.554208v1.abstract)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b423d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports.\n",
    "import os\n",
    "import imageio.v3 as imageio\n",
    "\n",
    "# Load the function to start the segment anything napari plugin.\n",
    "# (Note: the tool can also be started as a napari plugin.)\n",
    "from micro_sam.sam_annotator import annotator_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ccc22-1c40-4c30-a3a7-9b4d1804131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will download and unpack the data and do some further data preparation.\n",
    "# It will only be executed if the data has not been downloaded yet.\n",
    "data_dir = \"../data\"\n",
    "if os.path.exists(data_dir):\n",
    "    print(\"The data is downloaded already.\")\n",
    "else:\n",
    "    utils.prepare_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example image.\n",
    "image_path = os.path.join(data_dir, \"train\", \"gt_image_030\", \"gt_image_030_serum_image.tif\")\n",
    "image = imageio.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a747f-bc90-4677-8d86-a85235888199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cutout so that we can focus on annotating fewer cells.\n",
    "image = image[:600, :600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb1ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the 2d annotation tool.\n",
    "# Here, we use a model that was fine-tuned by us on microscopy data.\n",
    "# We select it with the 'model_type' argument.\n",
    "# \"vit_b\" stands for the size of the model and \"_lm\" means that it is the model finetuned on light microscopy data.\n",
    "annotator_2d(image, model_type=\"vit_b_lm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9da249",
   "metadata": {},
   "source": [
    "Annotate some of the cell using the interactive annotation functionality. Try out different ways to annotate the cells, using box prompts, point prompts and combinations thereof. Which of these combinations works best?\n",
    "\n",
    "After you are done save the annotations as a tif file, load the saved tif and make sure that your annotations were saved correctly.\n",
    "- You can save the annotations by selecting the corresponding layer `committed_objects`, and then saveing it via `File->Save Selected Layer(s)...`\n",
    "\n",
    "You can find explanations for how to use the annotation tool [here](https://computational-cell-analytics.github.io/micro-sam/micro_sam.html#annotation-tools) and can watch [the video tutorial](https://www.youtube.com/watch?v=ket7bDUP9tI&list=PLwYZXQJ3f36GQPpKCrSbHjGiH39X4XjSO&index=1) to see a live demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737314a1-436f-45e0-9e78-26217eeddd68",
   "metadata": {},
   "source": [
    "### More Data Annotation Tools\n",
    "\n",
    "We also offer other napari based annotation tools building on Segment Anything for:\n",
    "- [Annotating volumetric data](https://computational-cell-analytics.github.io/micro-sam/micro_sam.html#annotator-3d)\n",
    "- [Annotating (2D image) timeseries for object tracking](https://computational-cell-analytics.github.io/micro-sam/micro_sam.html#annotator-tracking)\n",
    "- [Annotating 2D image data en bulk](https://github.com/computational-cell-analytics/micro-sam/blob/master/examples/image_series_annotator.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
