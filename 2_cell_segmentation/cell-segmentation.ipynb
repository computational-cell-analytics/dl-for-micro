{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f1166ee",
   "metadata": {},
   "source": [
    "## Cell Segmentation\n",
    "\n",
    "Now we bring the nucleus segmentation, and cell foreground and boundary predictions together in order to obtain the complete cell instance segmentation. Here, we use a seeded watershed, where we use the nucleus instances as seeds, use the cell boundary predictions as height map for the watershed and the cell foreground prediction as mask. We use the watershed functionality from [skimage](https://scikit-image.org/) for this.\n",
    "\n",
    "The goal of this lesson is to further explore post-processing for instance segmentation and to also learn how to quantitatively evaluate segmentation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports and functionality for network prediction and watershed.\n",
    "import os\n",
    "\n",
    "import bioimageio.core\n",
    "import h5py\n",
    "import napari\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from xarray import DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to folders with the data and predictions.\n",
    "# If you store the data somewhere else just change the 'data_folder' variable.\n",
    "\n",
    "data_folder = \"../data\"\n",
    "output_folder = os.path.join(data_folder, \"predictions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "712a0ba2",
   "metadata": {},
   "source": [
    "### 1. Implement Cell Segmentation\n",
    "\n",
    "First, we implement the watershed based cell segmentation and visually check it for a test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the model we have trained in the previous notebook.\n",
    "model_path = os.path.join(data_folder, \"trained_models/boundary-segmentation/boundary_segmentation_model.zip\")\n",
    "model = bioimageio.core.load_resource_description(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d0b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And load the serum channel as well as the nucleus segmentation for one of the test images.\n",
    "image_path = os.path.join(data_folder, \"test/gt_image_048.h5\")\n",
    "prediction_path = os.path.join(data_folder, \"predictions/gt_image_048.h5\")\n",
    "\n",
    "with h5py.File(image_path, \"r\") as f:\n",
    "    image = f[\"raw/serum_IgG/s0\"][:]\n",
    "    \n",
    "with h5py.File(prediction_path, \"r\") as f:\n",
    "    nuclei = f[\"/segmentations/nuclei/watershed_based\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we run prediction with the cell segmentation network.\n",
    "# For details on the bioimageio functionality see the previous notebook on nucleus segmentation.\n",
    "with bioimageio.core.create_prediction_pipeline(model) as pp:\n",
    "    input_ = DataArray(image[None, None], dims=tuple(\"bcyx\"))\n",
    "    pred = bioimageio.core.predict_with_padding(pp, input_, padding={\"x\": 16, \"y\": 16})[0].values.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the predictions visually.\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(image)\n",
    "viewer.add_image(pred)\n",
    "viewer.add_labels(nuclei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db9233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run watershed to get the cell instance segmentation.\n",
    "foreground, boundaries = pred\n",
    "foreground = foreground > 0.5\n",
    "cells = watershed(boundaries, markers=nuclei, mask=foreground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa6946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And check the result.\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(image)\n",
    "viewer.add_labels(cells)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76ff57d0",
   "metadata": {},
   "source": [
    "### 2. Apply to Test Images\n",
    "\n",
    "Now we apply this segmentation approach to all test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939dff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_images = glob(os.path.join(data_folder, \"test/*.h5\"))\n",
    "test_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3412039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the prediction and watershed in a function.\n",
    "def segment_cells(pp, image, nuclei):\n",
    "    input_ = DataArray(image[None, None], dims=tuple(\"bcyx\"))\n",
    "    pred = bioimageio.core.predict_with_padding(pp, input_, padding={\"x\": 16, \"y\": 16})[0].values.squeeze()\n",
    "    foreground, boundaries = pred\n",
    "    foreground = foreground > 0.5\n",
    "    cells = watershed(boundaries, markers=nuclei, mask=foreground)\n",
    "    return cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9260e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And run this function for all test images, saving the results to hdf5.\n",
    "with bioimageio.core.create_prediction_pipeline(model) as pp:\n",
    "    for path in tqdm(test_images):\n",
    "        out_path = os.path.join(output_folder, os.path.basename(path))\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            image = f[\"raw/serum_IgG/s0\"][:]\n",
    "        with h5py.File(out_path, \"r\") as f:\n",
    "            nuclei = f[\"segmentations/nuclei/watershed_based\"][:]\n",
    "        cells = segment_cells(pp, image, nuclei)\n",
    "        with h5py.File(out_path, \"a\") as f:\n",
    "            f.create_dataset(\"segmentations/cells/watershed_based\", data=cells, compression=\"gzip\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcd3a91e",
   "metadata": {},
   "source": [
    "### 3.  Evaluate Cell Segmentation\n",
    "\n",
    "We can now also quantitatively evaluate the cell segementation. We use the AP50 evaluation metric for it. It measures the [precision](https://en.wikipedia.org/wiki/Precision_and_recall) of the matches between the predicted segmentation and ground-truth segmentation. This is a standard evaluation metric for instance segmentations, and we use the implementation from [elf](https://github.com/constantinpape/elf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3febff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from elf.evaluation import matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = glob(os.path.join(output_folder, \"*.h5\"))\n",
    "predictions.sort()\n",
    "assert len(predictions) == len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_scores = []\n",
    "for image_path, pred_path in zip(test_images, predictions):\n",
    "    with h5py.File(image_path, \"r\") as f:\n",
    "        ground_truth = f[\"labels/cells/s0\"][:]\n",
    "    with h5py.File(pred_path, \"r\") as f:\n",
    "        segmentation = f[\"segmentations/cells/watershed_based\"][:]\n",
    "    evaluation_scores.append(matching(segmentation, ground_truth)[\"precision\"])\n",
    "evaluation_score = np.mean(evaluation_scores)\n",
    "print(\"The AP50 score for the cell segmentation is\", evaluation_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "612f418a",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "- If you have trained different segmentation models in the previous notebook `torchem-train-cell-membrane-segmentation`, then compare the evaluation results between them.\n",
    "- [Cellpose](https://github.com/MouseLand/cellpose) is a generalist method for cell segmentation that can directly be applied to our data. Run segmentation for the test images with it and compare the evaluation scores.\n",
    "    - We are also working on adding a notebook that shows how to apply Cellpose to this data `cellpose_pretrained-cell-segmentation`, but this is work in progress."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d62d52d",
   "metadata": {},
   "source": [
    "### What's next\n",
    "\n",
    "Now that we have obtained a cell classification we turn to classifying the cells into infected vs. non-infected in `3_cell_classification/pytorch_train-infection-classifier.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
